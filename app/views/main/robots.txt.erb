# See https://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-Agent: *
# Disallow: /

# Global rules
User-agent: *
Disallow: /*.aspx*
Disallow: */pdf_productsheet/pdfproduct/*
Sitemap: <%= sitemap_url(format: 'xml', host: website.brand.default_website.url).gsub(/\?.*/, '') %>

# Yandex tries to pull support page as a jpeg for some reason
User-agent: Yandex
Disallow: /en-US/support.jpg
Disallow: /en/support.jpg

# Majestic12 bot hammers the site with DoS-style traffic
User-agent: MJ12bot
Disallow: /

# Bing rules
User-agent: Bingbot
Crawl-delay: 4.5
